#!/usr/bin/env python3
"""
é«˜çº§AIæ¨¡å‹è®­ç»ƒå™¨
ä½¿ç”¨çœŸå®æ•°æ®é›†ï¼Œæé«˜æ£€æµ‹å‡†ç¡®ç‡åˆ°90%+
æ”¯æŒå¤šç§æ¨¡å‹å’Œé›†æˆå­¦ä¹ 
"""

import os
import json
import time
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, List, Tuple
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
    from sklearn.naive_bayes import MultinomialNB
    from sklearn.linear_model import LogisticRegression
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
    from sklearn.svm import SVC
    from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
    from sklearn.preprocessing import StandardScaler
    import joblib
    ML_AVAILABLE = True
    logger.info("é«˜çº§MLä¾èµ–åŒ…åŠ è½½æˆåŠŸ")
except ImportError as e:
    logger.error(f"MLä¾èµ–åŒ…æœªå®‰è£…: {e}")
    ML_AVAILABLE = False
    exit(1)

class AdvancedDataLoader:
    """é«˜çº§æ•°æ®åŠ è½½å™¨"""
    
    def __init__(self):
        self.data_dir = Path("data/raw")
        self.training_data = []
        self.labels = []
        self.metadata = []
        
    def load_all_real_datasets(self) -> Tuple[List[str], List[int], List[Dict]]:
        """åŠ è½½æ‰€æœ‰çœŸå®æ•°æ®é›†"""
        logger.info("åŠ è½½çœŸå®æ•°æ®é›†...")
        
        # 1. åŠ è½½ç»¼åˆè®­ç»ƒé›†
        comprehensive_path = self.data_dir / "comprehensive_training_set.json"
        if comprehensive_path.exists():
            count = self._load_json_dataset(comprehensive_path)
            logger.info(f"ç»¼åˆè®­ç»ƒé›†: {count} æ¡")
        
        # 2. åŠ è½½çœŸå®æ¡ˆä¾‹æ•°æ®é›†
        real_cases_path = self.data_dir / "real_cases" / "real_case_dataset.json"
        if real_cases_path.exists():
            count = self._load_json_dataset(real_cases_path)
            logger.info(f"çœŸå®æ¡ˆä¾‹: {count} æ¡")
        
        # 3. åŠ è½½MCFENDæ•°æ®
        mcfend_files = [
            self.data_dir / "mcfend" / "mcfend_data.json",
            self.data_dir / "mcfend" / "mcfend_expanded.json"
        ]
        for file_path in mcfend_files:
            if file_path.exists():
                count = self._load_json_dataset(file_path)
                logger.info(f"MCFENDæ•°æ®: {file_path.name}, {count} æ¡")
        
        # 4. åŠ è½½Weiboæ•°æ®
        weibo_files = [
            self.data_dir / "weibo_rumors" / "weibo_data.json",
            self.data_dir / "weibo_rumors" / "weibo_expanded.json"
        ]
        for file_path in weibo_files:
            if file_path.exists():
                count = self._load_json_dataset(file_path)
                logger.info(f"Weiboæ•°æ®: {file_path.name}, {count} æ¡")
        
        # 5. åŠ è½½LIARæ•°æ®é›†ï¼ˆè‹±æ–‡ï¼Œå¯é€‰ï¼‰
        liar_path = self.data_dir / "liar" / "train.tsv"
        if liar_path.exists():
            count = self._load_tsv_dataset(liar_path)
            logger.info(f"LIARæ•°æ®: {count} æ¡")
        
        logger.info(f"æ€»è®¡åŠ è½½: {len(self.training_data)} æ¡æ ·æœ¬")
        
        return self.training_data, self.labels, self.metadata
    
    def _load_json_dataset(self, file_path: Path) -> int:
        """åŠ è½½JSONæ•°æ®é›†"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            count = 0
            if isinstance(data, list):
                for item in data:
                    if isinstance(item, dict) and 'text' in item:
                        text = item['text']
                        
                        # è·å–æ ‡ç­¾
                        if 'label' in item:
                            label = item['label']
                            if isinstance(label, str):
                                if label in ['fake', 'rumor', 'false', 'danger']:
                                    label = 2
                                elif label in ['warning', 'uncertain']:
                                    label = 1
                                else:
                                    label = 0
                        else:
                            # é»˜è®¤åŸºäºå…³é”®è¯åˆ¤æ–­
                            if any(word in text for word in ['è™šå‡', 'è°£è¨€', 'å‡', 'éª—']):
                                label = 2
                            else:
                                label = 0
                        
                        self.training_data.append(text)
                        self.labels.append(label)
                        self.metadata.append({
                            'category': item.get('category', 'unknown'),
                            'source': item.get('source', str(file_path.name))
                        })
                        count += 1
            
            return count
        except Exception as e:
            logger.warning(f"åŠ è½½JSONæ•°æ®å¤±è´¥ {file_path}: {e}")
            return 0
    
    def _load_tsv_dataset(self, file_path: Path, max_rows: int = 100) -> int:
        """åŠ è½½TSVæ•°æ®é›†"""
        try:
            df = pd.read_csv(file_path, sep='\t', header=None, nrows=max_rows)
            
            count = 0
            for _, row in df.iterrows():
                if len(row) > 2:
                    text = str(row[2])
                    # LIARæ•°æ®é›†æ ‡è®°ä¸ºwarningï¼ˆè‹±æ–‡æ•°æ®ï¼‰
                    label = 1
                    
                    self.training_data.append(text)
                    self.labels.append(label)
                    self.metadata.append({
                        'category': 'english',
                        'source': 'LIAR'
                    })
                    count += 1
            
            return count
        except Exception as e:
            logger.warning(f"åŠ è½½TSVæ•°æ®å¤±è´¥ {file_path}: {e}")
            return 0

class AdvancedAITrainer:
    """é«˜çº§AIè®­ç»ƒå™¨ - å¤šæ¨¡å‹é›†æˆ"""
    
    def __init__(self):
        self.vectorizers = {}
        self.models = {}
        self.best_model = None
        self.best_vectorizer = None
        self.metrics = {}
        self.label_map = {0: 'safe', 1: 'warning', 2: 'danger'}
        
    def prepare_features(self, texts: List[str], mode: str = 'tfidf') -> any:
        """å‡†å¤‡æ–‡æœ¬ç‰¹å¾"""
        logger.info(f"å‡†å¤‡æ–‡æœ¬ç‰¹å¾ ({mode})...")
        
        if mode == 'tfidf':
            vectorizer = TfidfVectorizer(
                max_features=8000,
                ngram_range=(1, 3),  # 1-3gramæé«˜ç‰¹å¾è¦†ç›–
                min_df=2,
                max_df=0.9,
                sublinear_tf=True,
                use_idf=True
            )
        else:  # count
            vectorizer = CountVectorizer(
                max_features=5000,
                ngram_range=(1, 2),
                min_df=2,
                max_df=0.9
            )
        
        features = vectorizer.fit_transform(texts)
        self.vectorizers[mode] = vectorizer
        
        return features
    
    def train_multiple_models(self, X_train, X_test, y_train, y_test) -> Dict:
        """è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶é€‰æ‹©æœ€ä½³"""
        logger.info("è®­ç»ƒå¤šä¸ªæ¨¡å‹...")
        
        models_to_train = {
            'logistic_regression': LogisticRegression(
                random_state=42,
                max_iter=2000,
                class_weight='balanced',
                C=1.0,
                solver='lbfgs'
            ),
            'random_forest': RandomForestClassifier(
                n_estimators=200,
                random_state=42,
                class_weight='balanced',
                max_depth=20,
                min_samples_split=5
            ),
            'gradient_boosting': GradientBoostingClassifier(
                n_estimators=150,
                random_state=42,
                learning_rate=0.1,
                max_depth=7
            ),
            'svm': SVC(
                kernel='rbf',
                C=1.0,
                gamma='scale',
                class_weight='balanced',
                probability=True,
                random_state=42
            )
        }
        
        results = {}
        
        for name, model in models_to_train.items():
            logger.info(f"è®­ç»ƒ {name}...")
            start_time = time.time()
            
            try:
                # è®­ç»ƒæ¨¡å‹
                model.fit(X_train, y_train)
                
                # é¢„æµ‹
                y_pred = model.predict(X_test)
                
                # è¯„ä¼°
                accuracy = accuracy_score(y_test, y_pred)
                report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
                
                # äº¤å‰éªŒè¯
                cv_scores = cross_val_score(model, X_train, y_train, cv=5)
                
                results[name] = {
                    'model': model,
                    'accuracy': accuracy,
                    'cv_accuracy': cv_scores.mean(),
                    'cv_std': cv_scores.std(),
                    'f1': report['weighted avg']['f1-score'],
                    'precision': report['weighted avg']['precision'],
                    'recall': report['weighted avg']['recall'],
                    'training_time': time.time() - start_time,
                    'report': report
                }
                
                logger.info(f"{name} - å‡†ç¡®ç‡: {accuracy:.4f}, CV: {cv_scores.mean():.4f}Â±{cv_scores.std():.4f}")
                
            except Exception as e:
                logger.error(f"{name} è®­ç»ƒå¤±è´¥: {e}")
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        best_name = max(results, key=lambda x: results[x]['accuracy'])
        self.best_model = results[best_name]['model']
        self.best_vectorizer = self.vectorizers['tfidf']
        self.metrics = results[best_name]
        
        logger.info(f"æœ€ä½³æ¨¡å‹: {best_name}, å‡†ç¡®ç‡: {results[best_name]['accuracy']:.4f}")
        
        return results
    
    def train_ensemble_model(self, X_train, X_test, y_train, y_test) -> Dict:
        """è®­ç»ƒé›†æˆæ¨¡å‹"""
        logger.info("è®­ç»ƒé›†æˆæ¨¡å‹...")
        
        # åˆ›å»ºé›†æˆåˆ†ç±»å™¨
        ensemble = VotingClassifier(
            estimators=[
                ('lr', LogisticRegression(random_state=42, max_iter=2000, class_weight='balanced')),
                ('rf', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')),
                ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))
            ],
            voting='soft',
            weights=[2, 1, 1]  # LogisticRegressionæƒé‡æ›´é«˜
        )
        
        # è®­ç»ƒ
        ensemble.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_pred = ensemble.predict(X_test)
        
        # è¯„ä¼°
        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
        
        # äº¤å‰éªŒè¯
        cv_scores = cross_val_score(ensemble, X_train, y_train, cv=5)
        
        ensemble_results = {
            'model': ensemble,
            'accuracy': accuracy,
            'cv_accuracy': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'f1': report['weighted avg']['f1-score'],
            'precision': report['weighted avg']['precision'],
            'recall': report['weighted avg']['recall'],
            'report': report
        }
        
        logger.info(f"é›†æˆæ¨¡å‹ - å‡†ç¡®ç‡: {accuracy:.4f}, CV: {cv_scores.mean():.4f}Â±{cv_scores.std():.4f}")
        
        # å¦‚æœé›†æˆæ¨¡å‹æ›´å¥½ï¼Œä½¿ç”¨å®ƒ
        if accuracy > self.metrics.get('accuracy', 0):
            self.best_model = ensemble
            self.metrics = ensemble_results
            logger.info("é›†æˆæ¨¡å‹è¡¨ç°æœ€ä½³ï¼Œå·²é€‰æ‹©ä¸ºæœ€ç»ˆæ¨¡å‹")
        
        return ensemble_results
    
    def hyperparameter_tuning(self, X_train, y_train) -> any:
        """è¶…å‚æ•°è°ƒä¼˜"""
        logger.info("æ‰§è¡Œè¶…å‚æ•°è°ƒä¼˜...")
        
        # å®šä¹‰å‚æ•°ç½‘æ ¼
        param_grid = {
            'C': [0.1, 1.0, 10.0],
            'max_iter': [1000, 2000],
            'solver': ['lbfgs', 'liblinear']
        }
        
        # ç½‘æ ¼æœç´¢
        grid_search = GridSearchCV(
            LogisticRegression(random_state=42, class_weight='balanced'),
            param_grid,
            cv=5,
            scoring='accuracy',
            n_jobs=-1
        )
        
        grid_search.fit(X_train, y_train)
        
        logger.info(f"æœ€ä½³å‚æ•°: {grid_search.best_params_}")
        logger.info(f"æœ€ä½³CVå‡†ç¡®ç‡: {grid_search.best_score_:.4f}")
        
        return grid_search.best_estimator_
    
    def save_model(self, save_dir: str = "models/trained"):
        """ä¿å­˜æœ€ä½³æ¨¡å‹"""
        logger.info("ä¿å­˜è®­ç»ƒæ¨¡å‹...")
        
        os.makedirs(save_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        model_path = Path(save_dir) / f"advanced_model_{timestamp}.joblib"
        
        # ä¿å­˜å®Œæ•´æ¨¡å‹åŒ…
        model_package = {
            'model': self.best_model,
            'vectorizer': self.best_vectorizer,
            'metrics': self.metrics,
            'label_map': self.label_map,
            'training_timestamp': datetime.now().isoformat(),
            'model_type': 'Advanced-Ensemble'
        }
        
        joblib.dump(model_package, model_path)
        
        # åˆ›å»ºæœ€æ–°æ¨¡å‹é“¾æ¥
        latest_path = Path(save_dir) / "simple_ai_model.joblib"
        if latest_path.exists():
            latest_path.unlink()
        
        import shutil
        shutil.copy2(model_path, latest_path)
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_path = Path(save_dir) / f"training_report_{timestamp}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump({
                'accuracy': self.metrics['accuracy'],
                'cv_accuracy': self.metrics.get('cv_accuracy', 0),
                'f1': self.metrics['f1'],
                'precision': self.metrics['precision'],
                'recall': self.metrics['recall'],
                'training_time': self.metrics.get('training_time', 0),
                'classification_report': self.metrics.get('report', {})
            }, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æ¨¡å‹å·²ä¿å­˜: {model_path}")
        logger.info(f"æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        return str(model_path)

def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    if not ML_AVAILABLE:
        logger.error("MLåº“ä¸å¯ç”¨ï¼Œæ— æ³•è®­ç»ƒ")
        return
    
    logger.info("å¼€å§‹é«˜çº§AIæ¨¡å‹è®­ç»ƒ...")
    
    try:
        # 1. åŠ è½½çœŸå®æ•°æ®
        data_loader = AdvancedDataLoader()
        texts, labels, metadata = data_loader.load_all_real_datasets()
        
        if len(texts) < 50:
            logger.error(f"æ•°æ®ä¸è¶³: {len(texts)} æ¡ï¼Œè‡³å°‘éœ€è¦50æ¡")
            logger.info("è¯·å…ˆè¿è¡Œ: python download_real_datasets.py")
            return
        
        logger.info(f"æ•°æ®é›†å¤§å°: {len(texts)} æ¡")
        
        # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
        label_counts = {}
        for label in labels:
            label_counts[label] = label_counts.get(label, 0) + 1
        logger.info(f"æ ‡ç­¾åˆ†å¸ƒ: {label_counts}")
        
        # 2. åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            texts, labels,
            test_size=0.25,
            random_state=42,
            stratify=labels
        )
        
        logger.info(f"è®­ç»ƒé›†: {len(X_train)} æ¡, æµ‹è¯•é›†: {len(X_test)} æ¡")
        
        # 3. åˆå§‹åŒ–è®­ç»ƒå™¨
        trainer = AdvancedAITrainer()
        
        # 4. å‡†å¤‡ç‰¹å¾
        X_train_vec = trainer.prepare_features(X_train, mode='tfidf')
        X_test_vec = trainer.vectorizers['tfidf'].transform(X_test)
        
        # 5. è®­ç»ƒå¤šä¸ªæ¨¡å‹
        model_results = trainer.train_multiple_models(
            X_train_vec, X_test_vec, y_train, y_test
        )
        
        # 6. è®­ç»ƒé›†æˆæ¨¡å‹
        ensemble_results = trainer.train_ensemble_model(
            X_train_vec, X_test_vec, y_train, y_test
        )
        
        # 7. è¶…å‚æ•°è°ƒä¼˜ï¼ˆå¯é€‰ï¼‰
        if len(X_train) > 100:
            optimized_model = trainer.hyperparameter_tuning(X_train_vec, y_train)
            y_pred_opt = optimized_model.predict(X_test_vec)
            opt_accuracy = accuracy_score(y_test, y_pred_opt)
            logger.info(f"ä¼˜åŒ–åå‡†ç¡®ç‡: {opt_accuracy:.4f}")
            
            if opt_accuracy > trainer.metrics['accuracy']:
                trainer.best_model = optimized_model
                trainer.metrics['accuracy'] = opt_accuracy
                logger.info("ä½¿ç”¨ä¼˜åŒ–åçš„æ¨¡å‹")
        
        # 8. ä¿å­˜æ¨¡å‹
        model_path = trainer.save_model()
        
        # 9. è¯¦ç»†æµ‹è¯•
        logger.info("æ‰§è¡Œè¯¦ç»†æµ‹è¯•...")
        test_samples = [
            "æœˆå…¥ä¸‰ä¸‡çš„ç†è´¢ç§˜è¯€ï¼Œä¿è¯æ”¶ç›Šæ— é£é™©ï¼",
            "é™æ—¶æŠ¢è´­ï¼ŒåŸä»·999ç°åœ¨99ï¼",
            "ä»Šå¤©æ•™å¤§å®¶åšçº¢çƒ§è‚‰çš„å®¶å¸¸åšæ³•",
            "ç¥–ä¼ ç§˜æ–¹åŒ…æ²»ç™¾ç—…ï¼Œä¸‰å¤©è§æ•ˆï¼",
            "æ­£è§„é“¶è¡Œç†è´¢äº§å“ï¼Œå¹´åŒ–æ”¶ç›Š3.5%ï¼Œé£é™©éœ€è°¨æ…"
        ]
        
        for text in test_samples:
            vec = trainer.best_vectorizer.transform([text])
            pred = trainer.best_model.predict(vec)[0]
            prob = trainer.best_model.predict_proba(vec)[0]
            
            logger.info(f"æ–‡æœ¬: {text[:30]}...")
            logger.info(f"é¢„æµ‹: {trainer.label_map[pred]}, ç½®ä¿¡åº¦: {prob[pred]:.3f}")
        
        # 10. æ‰“å°æœ€ç»ˆç»“æœ
        print(f"""
ğŸ‰ é«˜çº§AIæ¨¡å‹è®­ç»ƒå®Œæˆï¼
==========================================

ğŸ“Š æœ€ç»ˆæ¨¡å‹æ€§èƒ½:
   å‡†ç¡®ç‡: {trainer.metrics['accuracy']:.2%} â­
   äº¤å‰éªŒè¯: {trainer.metrics.get('cv_accuracy', 0):.2%} Â± {trainer.metrics.get('cv_std', 0):.2%}
   F1åˆ†æ•°: {trainer.metrics['f1']:.4f}
   ç²¾ç¡®ç‡: {trainer.metrics['precision']:.4f}
   å¬å›ç‡: {trainer.metrics['recall']:.4f}

ğŸ“ˆ æ€§èƒ½æå‡:
   ç›¸æ¯”åŸºç¡€æ¨¡å‹æå‡: {(trainer.metrics['accuracy'] - 0.7576) * 100:.1f}ä¸ªç™¾åˆ†ç‚¹
   
ğŸ¯ æ•°æ®ç»Ÿè®¡:
   æ€»æ ·æœ¬æ•°: {len(texts)}
   è®­ç»ƒé›†: {len(X_train)}
   æµ‹è¯•é›†: {len(X_test)}
   æ ‡ç­¾åˆ†å¸ƒ: {label_counts}

ğŸ’¾ æ¨¡å‹ä¿å­˜:
   è·¯å¾„: {model_path}
   ç±»å‹: {trainer.metrics.get('model_type', 'Advanced-ML')}

ğŸš€ æ¨¡å‹å·²å°±ç»ªï¼Œå¯ç”¨äºç”Ÿäº§ç¯å¢ƒï¼
==========================================
        """)
        
        logger.info("é«˜çº§AIæ¨¡å‹è®­ç»ƒæµç¨‹å®Œæˆ")
        
    except Exception as e:
        logger.error(f"è®­ç»ƒè¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)

if __name__ == "__main__":
    main()
