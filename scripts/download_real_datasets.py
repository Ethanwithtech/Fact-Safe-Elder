"""
çœŸå®æ•°æ®é›†ä¸‹è½½è„šæœ¬
æä¾›çœŸå®å¯ç”¨çš„æ•°æ®é›†ä¸‹è½½é“¾æ¥å’Œå¤„ç†æ–¹æ³•
"""

import os
import json
import requests
import git
from pathlib import Path
from typing import Dict, List
import subprocess
import sys


class RealDatasetDownloader:
    """çœŸå®æ•°æ®é›†ä¸‹è½½å™¨"""
    
    def __init__(self, data_dir: str = "./data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True, parents=True)
        
        # çœŸå®å¯ç”¨çš„æ•°æ®é›†é…ç½®
        self.real_datasets = {
            "chinese_rumor": {
                "name": "ä¸­æ–‡è°£è¨€æ£€æµ‹æ•°æ®é›†",
                "description": "æ¸…åå¤§å­¦NLPç»„å‘å¸ƒçš„ä¸­æ–‡è°£è¨€æ•°æ®é›†",
                "repo_url": "https://github.com/thunlp/Chinese_Rumor_Dataset.git",
                "paper_url": "https://arxiv.org/abs/1701.09657",
                "size_mb": 50,
                "samples": 31669,
                "format": "json",
                "license": "MIT"
            },
            "fakenewsnet": {
                "name": "FakeNewsNetæ•°æ®é›†",
                "description": "ASUå‘å¸ƒçš„å¤šå¹³å°è™šå‡æ–°é—»æ•°æ®é›†",
                "repo_url": "https://github.com/KaiDMML/FakeNewsNet.git",
                "paper_url": "https://arxiv.org/abs/1809.01286",
                "size_mb": 1200,
                "samples": 23196,
                "format": "json",
                "license": "Apache-2.0"
            },
            "liar": {
                "name": "LIARè™šå‡ä¿¡æ¯æ•°æ®é›†",
                "description": "UCSBå‘å¸ƒçš„äº‹å®æ£€æŸ¥æ•°æ®é›†",
                "download_url": "https://www.cs.ucsb.edu/~william/data/liar_dataset.zip",
                "paper_url": "https://arxiv.org/abs/1705.00648",
                "size_mb": 50,
                "samples": 12836,
                "format": "tsv",
                "license": "CC BY-SA"
            },
            "weibo_rumors": {
                "name": "å¾®åšè°£è¨€ä¼ æ’­æ•°æ®é›†",
                "description": "é¦™æ¸¯ä¸­æ–‡å¤§å­¦å¾®åšè°£è¨€ä¼ æ’­ç ”ç©¶æ•°æ®",
                "repo_url": "https://github.com/majingCUHK/Rumor_RvNN.git",
                "paper_url": "https://www.ijcai.org/Proceedings/2018/0619.pdf", 
                "size_mb": 200,
                "samples": 15000,
                "format": "json",
                "license": "GPL-3.0"
            }
        }
        
        print("ğŸ”— çœŸå®æ•°æ®é›†ä¸‹è½½å™¨åˆå§‹åŒ–å®Œæˆ")
        self._print_dataset_info()
    
    def _print_dataset_info(self):
        """æ‰“å°æ•°æ®é›†ä¿¡æ¯"""
        print("\nğŸ“Š å¯ä¸‹è½½çš„çœŸå®æ•°æ®é›†:")
        for dataset_id, config in self.real_datasets.items():
            print(f"   ğŸ”¹ {dataset_id}: {config['name']}")
            print(f"      ğŸ“– æè¿°: {config['description']}")
            print(f"      ğŸ“ å¤§å°: {config['size_mb']}MB")
            print(f"      ğŸ“ˆ æ ·æœ¬: {config['samples']:,}æ¡")
            if 'repo_url' in config:
                print(f"      ğŸ”— ä»“åº“: {config['repo_url']}")
            if 'download_url' in config:
                print(f"      ğŸ“¥ ä¸‹è½½: {config['download_url']}")
            print(f"      ğŸ“œ è®ºæ–‡: {config['paper_url']}")
            print()
    
    def download_chinese_rumor(self):
        """ä¸‹è½½ä¸­æ–‡è°£è¨€æ•°æ®é›†"""
        print("ğŸ“¥ ä¸‹è½½ä¸­æ–‡è°£è¨€æ•°æ®é›†...")
        
        dataset_dir = self.data_dir / "raw" / "chinese_rumor"
        
        try:
            # å…‹éš†ä»“åº“
            print("ğŸ”„ å…‹éš†GitHubä»“åº“...")
            git.Repo.clone_from(
                "https://github.com/thunlp/Chinese_Rumor_Dataset.git",
                dataset_dir,
                depth=1  # åªä¸‹è½½æœ€æ–°ç‰ˆæœ¬
            )
            
            print("âœ… ä¸­æ–‡è°£è¨€æ•°æ®é›†ä¸‹è½½æˆåŠŸ")
            return dataset_dir
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            print("ğŸ”— è¯·æ‰‹åŠ¨è®¿é—®: https://github.com/thunlp/Chinese_Rumor_Dataset")
            return None
    
    def download_fakenewsnet(self):
        """ä¸‹è½½FakeNewsNetæ•°æ®é›†"""
        print("ğŸ“¥ ä¸‹è½½FakeNewsNetæ•°æ®é›†...")
        
        dataset_dir = self.data_dir / "raw" / "fakenewsnet"
        
        try:
            print("ğŸ”„ å…‹éš†GitHubä»“åº“...")
            git.Repo.clone_from(
                "https://github.com/KaiDMML/FakeNewsNet.git",
                dataset_dir,
                depth=1
            )
            
            print("âœ… FakeNewsNetæ•°æ®é›†ä¸‹è½½æˆåŠŸ")
            return dataset_dir
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            print("ğŸ”— è¯·æ‰‹åŠ¨è®¿é—®: https://github.com/KaiDMML/FakeNewsNet")
            return None
    
    def download_liar_dataset(self):
        """ä¸‹è½½LIARæ•°æ®é›†"""
        print("ğŸ“¥ ä¸‹è½½LIARæ•°æ®é›†...")
        
        dataset_dir = self.data_dir / "raw" / "liar"
        dataset_dir.mkdir(exist_ok=True, parents=True)
        
        try:
            # ç›´æ¥ä¸‹è½½zipæ–‡ä»¶
            url = "https://www.cs.ucsb.edu/~william/data/liar_dataset.zip"
            
            print("ğŸ”„ ä¸‹è½½zipæ–‡ä»¶...")
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            zip_path = dataset_dir / "liar_dataset.zip"
            with open(zip_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            
            # è§£å‹
            print("ğŸ“¦ è§£å‹æ–‡ä»¶...")
            import zipfile
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(dataset_dir)
            
            zip_path.unlink()  # åˆ é™¤zipæ–‡ä»¶
            
            print("âœ… LIARæ•°æ®é›†ä¸‹è½½æˆåŠŸ")
            return dataset_dir
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            print("ğŸ”— è¯·æ‰‹åŠ¨ä¸‹è½½: https://www.cs.ucsb.edu/~william/data/liar_dataset.zip")
            return None
    
    def download_weibo_rumors(self):
        """ä¸‹è½½å¾®åšè°£è¨€æ•°æ®é›†"""
        print("ğŸ“¥ ä¸‹è½½å¾®åšè°£è¨€æ•°æ®é›†...")
        
        dataset_dir = self.data_dir / "raw" / "weibo_rumors"
        
        try:
            print("ğŸ”„ å…‹éš†GitHubä»“åº“...")
            git.Repo.clone_from(
                "https://github.com/majingCUHK/Rumor_RvNN.git",
                dataset_dir,
                depth=1
            )
            
            print("âœ… å¾®åšè°£è¨€æ•°æ®é›†ä¸‹è½½æˆåŠŸ")
            return dataset_dir
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            print("ğŸ”— è¯·æ‰‹åŠ¨è®¿é—®: https://github.com/majingCUHK/Rumor_RvNN")
            return None
    
    def download_all_available(self):
        """ä¸‹è½½æ‰€æœ‰å¯ç”¨çš„çœŸå®æ•°æ®é›†"""
        print("ğŸ¯ å¼€å§‹ä¸‹è½½æ‰€æœ‰çœŸå®æ•°æ®é›†...")
        
        results = {}
        
        # ä¾æ¬¡å°è¯•ä¸‹è½½
        datasets_methods = [
            ("chinese_rumor", self.download_chinese_rumor),
            ("fakenewsnet", self.download_fakenewsnet), 
            ("liar", self.download_liar_dataset),
            ("weibo_rumors", self.download_weibo_rumors)
        ]
        
        for dataset_id, download_method in datasets_methods:
            try:
                result = download_method()
                results[dataset_id] = "success" if result else "failed"
            except Exception as e:
                print(f"âŒ {dataset_id} ä¸‹è½½å¼‚å¸¸: {e}")
                results[dataset_id] = "error"
        
        # æ˜¾ç¤ºä¸‹è½½ç»“æœ
        print("\nğŸ“Š ä¸‹è½½ç»“æœæ±‡æ€»:")
        for dataset_id, status in results.items():
            config = self.real_datasets.get(dataset_id, {})
            name = config.get('name', dataset_id)
            
            if status == "success":
                print(f"   âœ… {name}: ä¸‹è½½æˆåŠŸ")
            else:
                print(f"   âŒ {name}: ä¸‹è½½å¤±è´¥")
                if 'repo_url' in config:
                    print(f"      ğŸ“ æ‰‹åŠ¨è®¿é—®: {config['repo_url']}")
                elif 'download_url' in config:
                    print(f"      ğŸ“ æ‰‹åŠ¨ä¸‹è½½: {config['download_url']}")
        
        return results
    
    def install_git_if_needed(self):
        """æ£€æŸ¥å¹¶å®‰è£…Gitï¼ˆå¦‚æœéœ€è¦ï¼‰"""
        try:
            subprocess.run(["git", "--version"], 
                         capture_output=True, check=True)
            print("âœ… Git å·²å®‰è£…")
            return True
        except:
            print("âŒ Git æœªå®‰è£…æˆ–ä¸å¯ç”¨")
            print("ğŸ”— è¯·å®‰è£…Git: https://git-scm.com/download/win")
            print("   æˆ–è€…ä½¿ç”¨æ‰‹åŠ¨ä¸‹è½½æ–¹å¼")
            return False


def print_manual_download_guide():
    """æ‰“å°æ‰‹åŠ¨ä¸‹è½½æŒ‡å—"""
    print("""
ğŸ”— æ‰‹åŠ¨ä¸‹è½½æŒ‡å—

å¦‚æœè‡ªåŠ¨ä¸‹è½½å¤±è´¥ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ‰‹åŠ¨ä¸‹è½½ï¼š

ğŸ“Š ä¼˜å…ˆæ¨èï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰ï¼š

1. ğŸ‡¨ğŸ‡³ ä¸­æ–‡è°£è¨€æ•°æ®é›† (æœ€é‡è¦)
   - è®¿é—®: https://github.com/thunlp/Chinese_Rumor_Dataset
   - ç‚¹å‡»ç»¿è‰²"Code"æŒ‰é’® â†’ Download ZIP
   - è§£å‹åˆ°: D:\\Projects\\Fact-Safe-Elder\\data\\raw\\chinese_rumor\\

2. ğŸ“° LIARæ•°æ®é›† (æ¨è)
   - ç›´æ¥ä¸‹è½½: https://www.cs.ucsb.edu/~william/data/liar_dataset.zip
   - è§£å‹åˆ°: D:\\Projects\\Fact-Safe-Elder\\data\\raw\\liar\\

3. ğŸŒ FakeNewsNet (å¯é€‰)
   - è®¿é—®: https://github.com/KaiDMML/FakeNewsNet
   - ä¸‹è½½æ•°æ®æ–‡ä»¶åˆ°: D:\\Projects\\Fact-Safe-Elder\\data\\raw\\fakenewsnet\\

4. ğŸ“± å¾®åšè°£è¨€æ•°æ®é›† (å¯é€‰)
   - è®¿é—®: https://github.com/majingCUHK/Rumor_RvNN
   - ä¸‹è½½åˆ°: D:\\Projects\\Fact-Safe-Elder\\data\\raw\\weibo_rumors\\

ğŸ“ ç›®å½•ç»“æ„ç¤ºä¾‹:
D:\\Projects\\Fact-Safe-Elder\\data\\
â”œâ”€â”€ raw\\
â”‚   â”œâ”€â”€ chinese_rumor\\
â”‚   â”‚   â”œâ”€â”€ train.json
â”‚   â”‚   â”œâ”€â”€ test.json
â”‚   â”‚   â””â”€â”€ val.json
â”‚   â”œâ”€â”€ liar\\
â”‚   â”‚   â”œâ”€â”€ train.tsv
â”‚   â”‚   â”œâ”€â”€ test.tsv
â”‚   â”‚   â””â”€â”€ valid.tsv
â”‚   â””â”€â”€ fakenewsnet\\
â”‚       â”œâ”€â”€ politifact_fake.json
â”‚       â””â”€â”€ politifact_real.json

ğŸ”§ ä¸‹è½½å®Œæˆåè¿è¡Œ:
python scripts/process_real_data.py --verify
""")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ çœŸå®æ•°æ®é›†ä¸‹è½½å·¥å…·")
    
    downloader = RealDatasetDownloader()
    
    # æ£€æŸ¥Git
    if not downloader.install_git_if_needed():
        print_manual_download_guide()
        return
    
    # å°è¯•ä¸‹è½½
    try:
        results = downloader.download_all_available()
        
        success_count = sum(1 for status in results.values() if status == "success")
        
        if success_count > 0:
            print(f"\nğŸ‰ æˆåŠŸä¸‹è½½ {success_count} ä¸ªæ•°æ®é›†ï¼")
        else:
            print("\nâš ï¸ è‡ªåŠ¨ä¸‹è½½å…¨éƒ¨å¤±è´¥ï¼Œè¯·ä½¿ç”¨æ‰‹åŠ¨ä¸‹è½½:")
            print_manual_download_guide()
            
    except Exception as e:
        print(f"âŒ ä¸‹è½½è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
        print_manual_download_guide()


if __name__ == "__main__":
    main()
